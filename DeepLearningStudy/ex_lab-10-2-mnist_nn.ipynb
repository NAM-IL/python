{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:blue\">[</span> lab-10-2-mnist_nn <span style=\"color:blue\">]</span>\n",
    "<p>출처: <a href=\"http://hunkim.github.io/ml/\" title=\"모두를 위한 머신러닝과 딥러닝의 강의\" target=\"blank\">모두를 위한 머신러닝과 딥러닝의 강의</a></p> <br/>\n",
    "> [Tensorflow Document(Tensor Transformations)](https://www.tensorflow.org/api_guides/python/array_ops)  <br/>\n",
    "> [CS 20SI: Tensorflow for Deep Learning Research](http://web.stanford.edu/class/cs20si/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow version: 1.2.0\n"
     ]
    }
   ],
   "source": [
    "# Lab 10 MNIST and NN\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "tf.set_random_seed(777)  # reproducibility\n",
    "\n",
    "print('tensorflow version: {0}'.format(tf.__version__))\n",
    "# print('numpy version: {0}'.format(np.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define paramaters for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# parameters\n",
    "learning_rate = 0.001\n",
    "training_epochs = 15\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Read in data\n",
    "> using TF Learn's built in function to load MNIST data to the folder data/mnist <br/>\n",
    "> Check out [MNIST For ML Beginners](https://www.tensorflow.org/get_started/mnist/beginners) for more information about the mnist dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "# Check out https://www.tensorflow.org/get_started/mnist/beginners for \n",
    "# more information about the mnist dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: create placeholders for features and labels\n",
    "> each image in the MNIST data is of shape 28*28 = 784 <br/>\n",
    "> therefore, each image is represented with a 1x784 tensor <br/>\n",
    "> there are 10 classes for each image, corresponding to digits 0 - 9.  <br/>\n",
    "> each lable is one hot vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# input place holders\n",
    "X = tf.placeholder(tf.float32, [None, 784])\n",
    "Y = tf.placeholder(tf.float32, [None, 10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: create weights and bias\n",
    "> w is initialized to random variables with normal random distribution   <br/>\n",
    "> b is initialized to random variables with normal random distribution "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# weights & bias for nn layers\n",
    "W1 = tf.Variable(tf.random_normal([784, 256]))\n",
    "b1 = tf.Variable(tf.random_normal([256]))\n",
    "\n",
    "W2 = tf.Variable(tf.random_normal([256, 256]))\n",
    "b2 = tf.Variable(tf.random_normal([256]))\n",
    "\n",
    "W3 = tf.Variable(tf.random_normal([256, 10]))\n",
    "b3 = tf.Variable(tf.random_normal([10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: build model\n",
    "> the model is passed through RELU to compute rectified linear, and then returns the logits. <br/>\n",
    "> this logits will be later passed through softmax layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "L1 = tf.nn.relu(tf.matmul(X, W1) + b1)\n",
    "L2 = tf.nn.relu(tf.matmul(L1, W2) + b2)\n",
    "\n",
    "hypothesis = tf.matmul(L2, W3) + b3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5: define loss function\n",
    "> use cross entropy of softmax of logits as the loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define cost/loss & optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=hypothesis, labels=Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 6: define training op\n",
    ">using Adam algorithm with learning rate of {learning_rate} to minimize loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize session & global variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# initialize\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 cost = 158.324838642\n",
      "Epoch: 0002 cost = 41.252933655\n",
      "Epoch: 0003 cost = 25.946591698\n",
      "Epoch: 0004 cost = 17.751157984\n",
      "Epoch: 0005 cost = 12.721524710\n",
      "Epoch: 0006 cost = 9.401667217\n",
      "Epoch: 0007 cost = 6.882740409\n",
      "Epoch: 0008 cost = 5.101480957\n",
      "Epoch: 0009 cost = 3.718600791\n",
      "Epoch: 0010 cost = 2.770275507\n",
      "Epoch: 0011 cost = 2.036773173\n",
      "Epoch: 0012 cost = 1.489278690\n",
      "Epoch: 0013 cost = 1.182101189\n",
      "Epoch: 0014 cost = 0.979347025\n",
      "Epoch: 0015 cost = 0.783439596\n",
      "Learning Finished!\n"
     ]
    }
   ],
   "source": [
    "# train my model\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0\n",
    "    total_batch = int(mnist.train.num_examples / batch_size)\n",
    "\n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        feed_dict = {X: batch_xs, Y: batch_ys}\n",
    "        c, _ = sess.run([cost, optimizer], feed_dict=feed_dict)\n",
    "        avg_cost += c / total_batch\n",
    "\n",
    "    print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.9f}'.format(avg_cost))\n",
    "\n",
    "print('Learning Finished!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test model and check accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9487\n",
      "Label:  [5]\n",
      "Prediction:  [5]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD8CAYAAABXXhlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1d9cc0bbeb8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'\\nEpoch: 0001 cost = 141.207671860\\nEpoch: 0002 cost = 38.788445864\\nEpoch: 0003 cost = 23.977515479\\nEpoch: 0004 cost = 16.315132428\\nEpoch: 0005 cost = 11.702554882\\nEpoch: 0006 cost = 8.573139748\\nEpoch: 0007 cost = 6.370995680\\nEpoch: 0008 cost = 4.537178684\\nEpoch: 0009 cost = 3.216900532\\nEpoch: 0010 cost = 2.329708954\\nEpoch: 0011 cost = 1.715552875\\nEpoch: 0012 cost = 1.189857912\\nEpoch: 0013 cost = 0.820965160\\nEpoch: 0014 cost = 0.624131458\\nEpoch: 0015 cost = 0.454633765\\nLearning Finished!\\nAccuracy: 0.9455\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test model and check accuracy\n",
    "correct_prediction = tf.equal(tf.argmax(hypothesis, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "print('Accuracy:', sess.run(accuracy, feed_dict={X: mnist.test.images, Y: mnist.test.labels}))\n",
    "\n",
    "# Get one and predict\n",
    "r = random.randint(0, mnist.test.num_examples - 1)\n",
    "print(\"Label: \", sess.run(tf.argmax(mnist.test.labels[r:r + 1], 1)))\n",
    "print(\"Prediction: \", sess.run(tf.argmax(hypothesis, 1), feed_dict={X: mnist.test.images[r:r + 1]}))\n",
    "\n",
    "plt.imshow(mnist.test.images[r:r + 1].reshape(28, 28), cmap='Greys', interpolation='nearest')\n",
    "plt.show()\n",
    "\n",
    "'''\n",
    "Epoch: 0001 cost = 141.207671860\n",
    "Epoch: 0002 cost = 38.788445864\n",
    "Epoch: 0003 cost = 23.977515479\n",
    "Epoch: 0004 cost = 16.315132428\n",
    "Epoch: 0005 cost = 11.702554882\n",
    "Epoch: 0006 cost = 8.573139748\n",
    "Epoch: 0007 cost = 6.370995680\n",
    "Epoch: 0008 cost = 4.537178684\n",
    "Epoch: 0009 cost = 3.216900532\n",
    "Epoch: 0010 cost = 2.329708954\n",
    "Epoch: 0011 cost = 1.715552875\n",
    "Epoch: 0012 cost = 1.189857912\n",
    "Epoch: 0013 cost = 0.820965160\n",
    "Epoch: 0014 cost = 0.624131458\n",
    "Epoch: 0015 cost = 0.454633765\n",
    "Learning Finished!\n",
    "Accuracy: 0.9455\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
