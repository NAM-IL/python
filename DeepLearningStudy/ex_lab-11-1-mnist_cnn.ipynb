{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:blue\">[</span> Lab 11-1 : MNIST and Convolutional Neural Network <span style=\"color:blue\">]</span>\n",
    "<p>출처: <a href=\"http://hunkim.github.io/ml/\" title=\"모두를 위한 머신러닝과 딥러닝의 강의\" target=\"blank\">모두를 위한 머신러닝과 딥러닝의 강의</a></p> <br/>\n",
    "> [CS 20SI: Tensorflow for Deep Learning Research](http://web.stanford.edu/class/cs20si/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Lab 11 MNIST and Convolutional Neural Network\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Read in data\n",
    "> using TF Learn's built in function to load MNIST data to the folder data/mnist <br/>\n",
    "> Check out [MNIST For ML Beginners](https://www.tensorflow.org/get_started/mnist/beginners) for more information about the mnist dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "\n",
    "# Check out https://www.tensorflow.org/get_started/mnist/beginners for\n",
    "# more information about the mnist dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Define paramaters for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# hyper parameters\n",
    "learning_rate = 0.001\n",
    "training_epochs = 15\n",
    "batch_size = 100\n",
    "\n",
    "tf.set_random_seed(777)  # reproducibility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Create placeholders for features and labels\n",
    "> each image in the MNIST data is of shape 28*28 = 784 <br/>\n",
    "> therefore, each image is represented with a 1x784 tensor <br/>\n",
    "> there are 10 classes for each image, corresponding to digits 0 - 9.  <br/>\n",
    "> each lable is one hot vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# input place holders\n",
    "X = tf.placeholder(tf.float32, [None, 784])\n",
    "X_img = tf.reshape(X, [-1, 28, 28, 1])   # img 28x28x1 (black/white)\n",
    "Y = tf.placeholder(tf.float32, [None, 10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Step 4 + 5: Create weights + do inference\n",
    "> the model is conv -> relu -> pool -> conv -> relu -> pool -> fully connected -> softmax\n",
    "\n",
    "\n",
    "> w is initialized to random variables with normal random distribution. <br/>\n",
    ">    Conv     -> (?, 28, 28, 32) <br/>\n",
    ">    Pool     -> (?, 14, 14, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------\n",
    "# L1 ImgIn shape=(?, 28, 28, 1)\n",
    "W1 = tf.Variable(tf.random_normal([3, 3, 1, 32], stddev=0.01))\n",
    "#    Conv     -> (?, 28, 28, 32)\n",
    "#    Pool     -> (?, 14, 14, 32)\n",
    "L1 = tf.nn.conv2d(X_img, W1, strides=[1, 1, 1, 1], padding='SAME')\n",
    "L1 = tf.nn.relu(L1)\n",
    "L1 = tf.nn.max_pool(L1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "'''\n",
    "Tensor(\"Conv2D:0\", shape=(?, 28, 28, 32), dtype=float32)\n",
    "Tensor(\"Relu:0\", shape=(?, 28, 28, 32), dtype=float32)\n",
    "Tensor(\"MaxPool:0\", shape=(?, 14, 14, 32), dtype=float32)\n",
    "'''\n",
    "# ---------------------------------------------------------------\n",
    "# L2 ImgIn shape=(?, 14, 14, 32)\n",
    "W2 = tf.Variable(tf.random_normal([3, 3, 32, 64], stddev=0.01))\n",
    "#    Conv      ->(?, 14, 14, 64)\n",
    "#    Pool      ->(?, 7, 7, 64)\n",
    "L2 = tf.nn.conv2d(L1, W2, strides=[1, 1, 1, 1], padding='SAME')\n",
    "L2 = tf.nn.relu(L2)\n",
    "L2 = tf.nn.max_pool(L2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "L2_flat = tf.reshape(L2, [-1, 7 * 7 * 64])\n",
    "\n",
    "'''\n",
    "Tensor(\"Conv2D_1:0\", shape=(?, 14, 14, 64), dtype=float32)\n",
    "Tensor(\"Relu_1:0\", shape=(?, 14, 14, 64), dtype=float32)\n",
    "Tensor(\"MaxPool_1:0\", shape=(?, 7, 7, 64), dtype=float32)\n",
    "Tensor(\"Reshape_1:0\", shape=(?, 3136), dtype=float32)\n",
    "'''\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# Final FC 7x7x64 inputs -> 10 outputs\n",
    "W3 = tf.get_variable(\"W3\", shape=[7 * 7 * 64, 10],\n",
    "                     initializer=tf.contrib.layers.xavier_initializer())\n",
    "b = tf.Variable(tf.random_normal([10]))\n",
    "logits = tf.matmul(L2_flat, W3) + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 6: Define loss function\n",
    "> use softmax cross entropy with logits as the loss function\n",
    "> compute mean cross entropy, softmax is applied internally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define cost/loss \n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 7: Define training op\n",
    "> using AdamOptimizer with learning rate of {learning_rate} to minimize cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize session & global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# initialize\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning started. It takes sometime.\n",
      "Epoch: 0001 cost = 0.342078431\n",
      "Epoch: 0002 cost = 0.092851951\n",
      "Epoch: 0003 cost = 0.068113291\n",
      "Epoch: 0004 cost = 0.055210830\n",
      "Epoch: 0005 cost = 0.046923109\n",
      "Epoch: 0006 cost = 0.041235309\n",
      "Epoch: 0007 cost = 0.035882169\n",
      "Epoch: 0008 cost = 0.031362815\n",
      "Epoch: 0009 cost = 0.027749437\n",
      "Epoch: 0010 cost = 0.024625990\n",
      "Epoch: 0011 cost = 0.022472894\n",
      "Epoch: 0012 cost = 0.018263866\n",
      "Epoch: 0013 cost = 0.016049490\n",
      "Epoch: 0014 cost = 0.015249646\n",
      "Epoch: 0015 cost = 0.013146065\n",
      "Learning Finished!\n"
     ]
    }
   ],
   "source": [
    "# train my model\n",
    "print('Learning started. It takes sometime.')\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0\n",
    "    total_batch = int(mnist.train.num_examples / batch_size)\n",
    "\n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        feed_dict = {X: batch_xs, Y: batch_ys}\n",
    "        c, _ = sess.run([cost, optimizer], feed_dict=feed_dict)\n",
    "        avg_cost += c / total_batch\n",
    "\n",
    "    print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.9f}'.format(avg_cost))\n",
    "\n",
    "print('Learning Finished!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the model and check accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9881\n",
      "Label:  [7]\n",
      "Prediction:  [7]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD8CAYAAABXXhlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1d8a6ceacf8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'\\nEpoch: 0001 cost = 0.340291267\\nEpoch: 0002 cost = 0.090731326\\nEpoch: 0003 cost = 0.064477619\\nEpoch: 0004 cost = 0.050683064\\nEpoch: 0005 cost = 0.041864835\\nEpoch: 0006 cost = 0.035760704\\nEpoch: 0007 cost = 0.030572132\\nEpoch: 0008 cost = 0.026207981\\nEpoch: 0009 cost = 0.022622454\\nEpoch: 0010 cost = 0.019055919\\nEpoch: 0011 cost = 0.017758641\\nEpoch: 0012 cost = 0.014156652\\nEpoch: 0013 cost = 0.012397016\\nEpoch: 0014 cost = 0.010693789\\nEpoch: 0015 cost = 0.009469977\\nLearning Finished!\\nAccuracy: 0.9885\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test model and check accuracy\n",
    "correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "print('Accuracy:', sess.run(accuracy, feed_dict={X: mnist.test.images, Y: mnist.test.labels}))\n",
    "\n",
    "# Get one and predict\n",
    "r = random.randint(0, mnist.test.num_examples - 1)\n",
    "print(\"Label: \", sess.run(tf.argmax(mnist.test.labels[r:r + 1], 1)))\n",
    "print(\"Prediction: \", sess.run(tf.argmax(logits, 1), feed_dict={X: mnist.test.images[r:r + 1]}))\n",
    "\n",
    "# show image\n",
    "plt.imshow(mnist.test.images[r:r + 1].reshape(28, 28), cmap='Greys', interpolation='nearest')\n",
    "plt.show()\n",
    "\n",
    "'''\n",
    "Epoch: 0001 cost = 0.340291267\n",
    "Epoch: 0002 cost = 0.090731326\n",
    "Epoch: 0003 cost = 0.064477619\n",
    "Epoch: 0004 cost = 0.050683064\n",
    "Epoch: 0005 cost = 0.041864835\n",
    "Epoch: 0006 cost = 0.035760704\n",
    "Epoch: 0007 cost = 0.030572132\n",
    "Epoch: 0008 cost = 0.026207981\n",
    "Epoch: 0009 cost = 0.022622454\n",
    "Epoch: 0010 cost = 0.019055919\n",
    "Epoch: 0011 cost = 0.017758641\n",
    "Epoch: 0012 cost = 0.014156652\n",
    "Epoch: 0013 cost = 0.012397016\n",
    "Epoch: 0014 cost = 0.010693789\n",
    "Epoch: 0015 cost = 0.009469977\n",
    "Learning Finished!\n",
    "Accuracy: 0.9885\n",
    "'''\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
