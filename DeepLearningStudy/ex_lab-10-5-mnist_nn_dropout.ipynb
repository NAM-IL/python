{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:blue\">[</span> lab-10-5-mnist_nn_dropout <span style=\"color:blue\">]</span>\n",
    "><p>출처: <a href=\"http://hunkim.github.io/ml/\" title=\"모두를 위한 머신러닝과 딥러닝의 강의\" target=\"blank\">모두를 위한 머신러닝과 딥러닝의 강의</a></p> <br/>\n",
    "> [Tensorflow Document(Tensor Transformations)](https://www.tensorflow.org/api_guides/python/array_ops)  <br/>\n",
    "> [CS 20SI: Tensorflow for Deep Learning Research](http://web.stanford.edu/class/cs20si/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Lab 10 MNIST and Dropout\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "tf.set_random_seed(777)  # reproducibility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define paramaters for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# parameters\n",
    "learning_rate = 0.001\n",
    "training_epochs = 15\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Read in data\n",
    "> using TF Learn's built in function to load MNIST data to the folder data/mnist <br/>\n",
    "> Check out [MNIST For ML Beginners](https://www.tensorflow.org/get_started/mnist/beginners) for more information about the mnist dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "# Check out https://www.tensorflow.org/get_started/mnist/beginners for\n",
    "# more information about the mnist dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: create placeholders for features and labels\n",
    "> each image in the MNIST data is of shape 28*28 = 784 <br/>\n",
    "> therefore, each image is represented with a 1x784 tensor <br/>\n",
    "> there are 10 classes for each image, corresponding to digits 0 - 9.  <br/>\n",
    "> each lable is one hot vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# input place holders\n",
    "X = tf.placeholder(tf.float32, [None, 784])\n",
    "Y = tf.placeholder(tf.float32, [None, 10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> dropout (keep_prob) rate  0.7 on training, but should be 1 for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dropout (keep_prob) rate  0.7 on training, but should be 1 for testing\n",
    "keep_prob = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: create weights and bias\n",
    "> weights & bias for nn layers ( [How to do Xavier initialization on TensorFlow\n",
    "](http://stackoverflow.com/questions/33640581/how-to-do-xavier-initialization-on-tensorflow) )<br/>\n",
    ">> w is initialized by using Xavier initializer.   <br/>\n",
    ">> b is initialized to random variables with normal random distribution. <br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# weights & bias for nn layers\n",
    "# http://stackoverflow.com/questions/33640581/how-to-do-xavier-initialization-on-tensorflow\n",
    "W1 = tf.get_variable(\"W1\", shape=[784, 512], initializer=tf.contrib.layers.xavier_initializer())\n",
    "b1 = tf.Variable(tf.random_normal([512]))\n",
    "\n",
    "W2 = tf.get_variable(\"W2\", shape=[512, 512], initializer=tf.contrib.layers.xavier_initializer())\n",
    "b2 = tf.Variable(tf.random_normal([512]))\n",
    "\n",
    "W3 = tf.get_variable(\"W3\", shape=[512, 512], initializer=tf.contrib.layers.xavier_initializer())\n",
    "b3 = tf.Variable(tf.random_normal([512]))\n",
    "\n",
    "W4 = tf.get_variable(\"W4\", shape=[512, 512], initializer=tf.contrib.layers.xavier_initializer())\n",
    "b4 = tf.Variable(tf.random_normal([512]))\n",
    "\n",
    "W5 = tf.get_variable(\"W5\", shape=[512, 10], initializer=tf.contrib.layers.xavier_initializer())\n",
    "b5 = tf.Variable(tf.random_normal([10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: build model\n",
    "> the model is passed through RELU to compute rectified linear, and then returns the logits. <br/>\n",
    "> this logits will be later passed through softmax layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "L1 = tf.nn.relu(tf.matmul(X, W1) + b1)\n",
    "L1 = tf.nn.dropout(L1, keep_prob=keep_prob)\n",
    "L2 = tf.nn.relu(tf.matmul(L1, W2) + b2)\n",
    "L2 = tf.nn.dropout(L2, keep_prob=keep_prob)\n",
    "L3 = tf.nn.relu(tf.matmul(L2, W3) + b3)\n",
    "L3 = tf.nn.dropout(L3, keep_prob=keep_prob)\n",
    "L4 = tf.nn.relu(tf.matmul(L3, W4) + b4)\n",
    "L4 = tf.nn.dropout(L4, keep_prob=keep_prob)\n",
    "hypothesis = tf.matmul(L4, W5) + b5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5: define loss function\n",
    "> use cross entropy of softmax of logits as the loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define cost/loss & optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=hypothesis, labels=Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 6: define training op\n",
    ">using Adam algorithm with learning rate of {learning_rate} to minimize loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize session & global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# initialize\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 cost = 0.471351691\n",
      "Epoch: 0002 cost = 0.171605674\n",
      "Epoch: 0003 cost = 0.131178645\n",
      "Epoch: 0004 cost = 0.108837361\n",
      "Epoch: 0005 cost = 0.093013735\n",
      "Epoch: 0006 cost = 0.085374823\n",
      "Epoch: 0007 cost = 0.076044019\n",
      "Epoch: 0008 cost = 0.070048312\n",
      "Epoch: 0009 cost = 0.063817517\n",
      "Epoch: 0010 cost = 0.062133964\n",
      "Epoch: 0011 cost = 0.057288595\n",
      "Epoch: 0012 cost = 0.051973078\n",
      "Epoch: 0013 cost = 0.051025491\n",
      "Epoch: 0014 cost = 0.049962570\n",
      "Epoch: 0015 cost = 0.047879591\n",
      "Learning Finished!\n"
     ]
    }
   ],
   "source": [
    "# train my model\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0\n",
    "    total_batch = int(mnist.train.num_examples / batch_size)\n",
    "\n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        feed_dict = {X: batch_xs, Y: batch_ys, keep_prob: 0.7}\n",
    "        c, _ = sess.run([cost, optimizer], feed_dict=feed_dict)\n",
    "        avg_cost += c / total_batch\n",
    "\n",
    "    print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.9f}'.format(avg_cost))\n",
    "\n",
    "print('Learning Finished!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test model and check accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9798\n",
      "Label:  [1]\n",
      "Prediction:  [1]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD8CAYAAABXXhlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nxmYxRQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1d1bd1e80b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'\\nEpoch: 0001 cost = 0.447322626\\nEpoch: 0002 cost = 0.157285590\\nEpoch: 0003 cost = 0.121884535\\nEpoch: 0004 cost = 0.098128681\\nEpoch: 0005 cost = 0.082901778\\nEpoch: 0006 cost = 0.075337573\\nEpoch: 0007 cost = 0.069752543\\nEpoch: 0008 cost = 0.060884363\\nEpoch: 0009 cost = 0.055276413\\nEpoch: 0010 cost = 0.054631256\\nEpoch: 0011 cost = 0.049675195\\nEpoch: 0012 cost = 0.049125314\\nEpoch: 0013 cost = 0.047231930\\nEpoch: 0014 cost = 0.041290121\\nEpoch: 0015 cost = 0.043621063\\nLearning Finished!\\nAccuracy: 0.9804\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test model and check accuracy\n",
    "correct_prediction = tf.equal(tf.argmax(hypothesis, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "print('Accuracy:', sess.run(accuracy, feed_dict={X: mnist.test.images, Y: mnist.test.labels, keep_prob: 1}))\n",
    "\n",
    "# Get one and predict\n",
    "r = random.randint(0, mnist.test.num_examples - 1)\n",
    "print(\"Label: \", sess.run(tf.argmax(mnist.test.labels[r:r + 1], 1)))\n",
    "print(\"Prediction: \", sess.run(tf.argmax(hypothesis, 1), feed_dict={X: mnist.test.images[r:r + 1], keep_prob: 1}))\n",
    "\n",
    "plt.imshow(mnist.test.images[r:r + 1].reshape(28, 28), cmap='Greys', interpolation='nearest')\n",
    "plt.show()\n",
    "\n",
    "'''\n",
    "Epoch: 0001 cost = 0.447322626\n",
    "Epoch: 0002 cost = 0.157285590\n",
    "Epoch: 0003 cost = 0.121884535\n",
    "Epoch: 0004 cost = 0.098128681\n",
    "Epoch: 0005 cost = 0.082901778\n",
    "Epoch: 0006 cost = 0.075337573\n",
    "Epoch: 0007 cost = 0.069752543\n",
    "Epoch: 0008 cost = 0.060884363\n",
    "Epoch: 0009 cost = 0.055276413\n",
    "Epoch: 0010 cost = 0.054631256\n",
    "Epoch: 0011 cost = 0.049675195\n",
    "Epoch: 0012 cost = 0.049125314\n",
    "Epoch: 0013 cost = 0.047231930\n",
    "Epoch: 0014 cost = 0.041290121\n",
    "Epoch: 0015 cost = 0.043621063\n",
    "Learning Finished!\n",
    "Accuracy: 0.9804\n",
    "'''\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
